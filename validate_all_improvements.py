#!/usr/bin/env python3
"""
Script para validar todas as melhorias implementadas em todos os 44 PDFs
"""

import os
import sys
from pathlib import Path
import fitz
import re
import time
import json
from datetime import datetime

# Adicionar o diret√≥rio atual ao path
sys.path.append(str(Path(__file__).parent))

from converter.pipeline import ConversionPipeline

def validate_all_improvements():
    """Valida todas as melhorias em todos os 44 PDFs"""
    
    # Diret√≥rios
    pdf_dir = "/home/andrade/Documentos/Meus Ebooks/Genesis: The Correct Timeline/Referencias em PDF"
    original_md_dir = "/home/andrade/Documentos/Meus Ebooks/Genesis: The Correct Timeline/Referencias em Markdown"
    test_output_dir = "/home/andrade/Documentos/Meus Ebooks/Genesis: The Correct Timeline/Referencias em Markdown"
    
    print("üî¨ VALIDA√á√ÉO COMPLETA DE TODAS AS MELHORIAS")
    print("="*60)
    print("‚úÖ Conflito de processamento corrigido")
    print("‚úÖ M√©trica de densidade adicionada")
    print("‚úÖ Extra√ß√£o de texto melhorada")
    print("‚úÖ Otimiza√ß√£o de par√°grafos implementada")
    print("="*60)
    
    # Criar diret√≥rio de teste
    test_dir = Path(test_output_dir)
    test_dir.mkdir(exist_ok=True)
    
    # Buscar todos os PDFs
    pdf_files = list(Path(pdf_dir).glob("*.pdf"))
    
    if not pdf_files:
        print(f"‚ùå Nenhum PDF encontrado em {pdf_dir}")
        return False
    
    print(f"\nüìÑ ENCONTRADOS {len(pdf_files)} ARQUIVOS PDF")
    print("-" * 40)
    
    # Criar pipeline com melhorias
    pipeline = ConversionPipeline(str(test_dir))
    
    # Resultados
    results = []
    successful_conversions = 0
    failed_conversions = 0
    total_start_time = time.time()
    
    print(f"\nüöÄ INICIANDO VALIDA√á√ÉO DE TODOS OS ARQUIVOS")
    print("-" * 40)
    
    for i, pdf_path in enumerate(pdf_files, 1):
        pdf_name = pdf_path.name
        original_md_path = Path(original_md_dir) / (pdf_name.replace('.pdf', '.md'))
        
        print(f"\n[{i:2d}/{len(pdf_files)}] Testando: {pdf_name}")
        
        try:
            # 1. An√°lise do PDF original
            pdf_info = analyze_pdf(pdf_path)
            
            # 2. Convers√£o com melhorias
            conversion_start = time.time()
            improved_md_path = pipeline.convert(str(pdf_path), f"improved_{pdf_name.replace('.pdf', '.md')}")
            conversion_time = time.time() - conversion_start
            
            # 3. An√°lise do resultado melhorado
            improved_info = analyze_markdown(improved_md_path)
            
            # 4. Calcular preserva√ß√£o em rela√ß√£o ao PDF original
            improved_char_preservation = improved_info['total_chars'] / pdf_info['total_chars'] * 100
            improved_word_preservation = improved_info['total_words'] / pdf_info['total_words'] * 100
            improved_info['preservation_rate'] = improved_char_preservation
            
            # 5. Compara√ß√£o com convers√£o original (se existir)
            comparison_info = {}
            if original_md_path.exists():
                original_info = analyze_markdown(original_md_path)
                comparison_info = compare_conversions(improved_info, original_info, pdf_info)
            
            # 6. Avalia√ß√£o da qualidade
            quality_score = evaluate_quality(improved_info, comparison_info)
            
            # 6. Coletar resultado
            result = {
                'filename': pdf_name,
                'pdf_info': pdf_info,
                'improved_info': improved_info,
                'comparison_info': comparison_info,
                'quality_score': quality_score,
                'conversion_time': conversion_time,
                'success': True
            }
            
            results.append(result)
            successful_conversions += 1
            
            # Exibir resumo
            print(f"   ‚úÖ Convers√£o: {conversion_time:.2f}s")
            print(f"   üìä Preserva√ß√£o: {improved_info['preservation_rate']:.1f}%")
            print(f"   üìà Densidade: {improved_info['density']:.3f}")
            print(f"   üéØ Score: {quality_score}/10")
            
            if comparison_info:
                improvement = comparison_info.get('density_improvement', 0)
                if improvement > 0:
                    print(f"   üöÄ Melhoria na densidade: {improvement:+.3f}")
            
        except Exception as e:
            print(f"   ‚ùå Erro: {e}")
            failed_conversions += 1
            
            result = {
                'filename': pdf_name,
                'error': str(e),
                'success': False
            }
            results.append(result)
    
    total_time = time.time() - total_start_time
    
    # Gerar relat√≥rio completo
    generate_comprehensive_report(results, total_time, successful_conversions, failed_conversions, test_output_dir)
    
    return successful_conversions, failed_conversions

def analyze_pdf(pdf_path):
    """Analisa um PDF individual"""
    doc = fitz.open(pdf_path)
    
    # Extrair informa√ß√µes b√°sicas
    total_chars = 0
    total_words = 0
    total_pages = len(doc)
    
    for page in doc:
        text = page.get_text()
        total_chars += len(text)
        total_words += len(re.findall(r'\b\w+\b', text.lower()))
    
    doc.close()
    
    return {
        'total_chars': total_chars,
        'total_words': total_words,
        'total_pages': total_pages,
        'avg_chars_per_page': total_chars / total_pages if total_pages > 0 else 0,
        'avg_words_per_page': total_words / total_pages if total_pages > 0 else 0
    }

def analyze_markdown(md_path):
    """Analisa um arquivo Markdown"""
    with open(md_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    lines = content.split('\n')
    words = re.findall(r'\b\w+\b', content.lower())
    
    # Calcular m√©tricas
    total_lines = len(lines)
    empty_lines = len([line for line in lines if line.strip() == ''])
    content_lines = total_lines - empty_lines
    density = 1 - (empty_lines / total_lines) if total_lines > 0 else 0
    
    # An√°lise de qualidade do texto
    sample_text = content[:2000]  # Primeiros 2000 caracteres para an√°lise
    words_together = len(re.findall(r'[a-z][A-Z]', sample_text))
    sentences = re.split(r'[.!?]', sample_text)
    broken_sentences = sum(1 for s in sentences if len(s.strip()) < 10 and len(s.strip()) > 0)
    
    # Par√°grafos
    paragraphs = [p.strip() for p in content.split('\n\n') if p.strip()]
    avg_paragraph_length = sum(len(p) for p in paragraphs) / len(paragraphs) if paragraphs else 0
    
    # T√≠tulos
    titles = re.findall(r'^#+\s+(.+)$', content, re.MULTILINE)
    
    return {
        'total_chars': len(content),
        'total_words': len(words),
        'total_lines': total_lines,
        'empty_lines': empty_lines,
        'content_lines': content_lines,
        'density': density,
        'words_together': words_together,
        'broken_sentences': broken_sentences,
        'paragraphs_count': len(paragraphs),
        'avg_paragraph_length': avg_paragraph_length,
        'titles_count': len(titles),
        'preservation_rate': 0  # Ser√° calculado na compara√ß√£o
    }

def compare_conversions(improved_info, original_info, pdf_info):
    """Compara convers√µes melhorada vs original"""
    
    # Calcular taxas de preserva√ß√£o
    improved_char_preservation = improved_info['total_chars'] / pdf_info['total_chars'] * 100
    improved_word_preservation = improved_info['total_words'] / pdf_info['total_words'] * 100
    original_char_preservation = original_info['total_chars'] / pdf_info['total_chars'] * 100
    original_word_preservation = original_info['total_words'] / pdf_info['total_words'] * 100
    
    # Melhorias
    char_improvement = improved_char_preservation - original_char_preservation
    word_improvement = improved_word_preservation - original_word_preservation
    density_improvement = improved_info['density'] - original_info['density']
    
    # Redu√ß√£o de linhas vazias
    original_empty_rate = original_info['empty_lines'] / original_info['total_lines'] if original_info['total_lines'] > 0 else 0
    improved_empty_rate = improved_info['empty_lines'] / improved_info['total_lines'] if improved_info['total_lines'] > 0 else 0
    empty_line_improvement = original_empty_rate - improved_empty_rate
    
    # Melhoria na qualidade do texto
    text_quality_improvement = 0
    if original_info['words_together'] > improved_info['words_together']:
        text_quality_improvement += 1
    if original_info['broken_sentences'] > improved_info['broken_sentences']:
        text_quality_improvement += 1
    
    return {
        'improved_char_preservation': improved_char_preservation,
        'improved_word_preservation': improved_word_preservation,
        'original_char_preservation': original_char_preservation,
        'original_word_preservation': original_word_preservation,
        'char_improvement': char_improvement,
        'word_improvement': word_improvement,
        'density_improvement': density_improvement,
        'empty_line_improvement': empty_line_improvement * 100,  # Em percentual
        'text_quality_improvement': text_quality_improvement
    }

def evaluate_quality(improved_info, comparison_info):
    """Avalia a qualidade da convers√£o melhorada"""
    score = 0
    
    # Pontua√ß√£o baseada na densidade
    if improved_info['density'] > 0.9:
        score += 3
    elif improved_info['density'] > 0.8:
        score += 2
    elif improved_info['density'] > 0.7:
        score += 1
    
    # Pontua√ß√£o baseada na qualidade do texto
    if improved_info['words_together'] < 5:
        score += 2
    elif improved_info['words_together'] < 10:
        score += 1
    
    if improved_info['broken_sentences'] < 5:
        score += 2
    elif improved_info['broken_sentences'] < 10:
        score += 1
    
    # Pontua√ß√£o baseada na estrutura
    if improved_info['avg_paragraph_length'] > 100:
        score += 1
    
    if improved_info['titles_count'] > 3:
        score += 1
    
    # Pontua√ß√£o baseada em melhorias (se compar√°vel)
    if comparison_info:
        if comparison_info.get('density_improvement', 0) > 0.05:
            score += 1
        if comparison_info.get('text_quality_improvement', 0) > 0:
            score += 1
    
    return min(score, 10)  # M√°ximo 10 pontos

def generate_comprehensive_report(results, total_time, successful_conversions, failed_conversions, output_dir):
    """Gera relat√≥rio abrangente dos resultados"""
    
    print(f"\nüìä RELAT√ìRIO COMPREENSIVO DE VALIDA√á√ÉO")
    print("="*60)
    
    # Estat√≠sticas gerais
    total_files = len(results)
    success_rate = successful_conversions / total_files * 100
    
    print(f"üìà ESTAT√çSTICAS GERAIS:")
    print(f"   Total de arquivos testados: {total_files}")
    print(f"   Convers√µes bem-sucedidas: {successful_conversions}")
    print(f"   Convers√µes falharam: {failed_conversions}")
    print(f"   Taxa de sucesso: {success_rate:.1f}%")
    print(f"   Tempo total: {total_time:.2f}s")
    print(f"   Tempo m√©dio por arquivo: {total_time/total_files:.2f}s")
    
    # Filtrar convers√µes bem-sucedidas
    successful_results = [r for r in results if r['success']]
    
    if not successful_results:
        print("‚ùå Nenhuma convers√£o bem-sucedida para an√°lise")
        return
    
    # An√°lise de qualidade
    quality_scores = [r['quality_score'] for r in successful_results]
    avg_quality = sum(quality_scores) / len(quality_scores)
    
    densities = [r['improved_info']['density'] for r in successful_results]
    avg_density = sum(densities) / len(densities)
    
    conversion_times = [r['conversion_time'] for r in successful_results]
    avg_conversion_time = sum(conversion_times) / len(conversion_times)
    
    print(f"\nüéØ AN√ÅLISE DE QUALIDADE:")
    print(f"   Score m√©dio de qualidade: {avg_quality:.2f}/10")
    print(f"   Densidade m√©dia: {avg_density:.3f}")
    print(f"   Tempo m√©dio de convers√£o: {avg_conversion_time:.2f}s")
    
    # An√°lise de melhorias (se houver compara√ß√µes)
    comparisons = [r for r in successful_results if r['comparison_info']]
    
    if comparisons:
        density_improvements = [r['comparison_info']['density_improvement'] for r in comparisons]
        avg_density_improvement = sum(density_improvements) / len(density_improvements)
        
        improved_files = sum(1 for r in comparisons if r['comparison_info']['density_improvement'] > 0)
        improvement_rate = improved_files / len(comparisons) * 100
        
        print(f"\nüöÄ AN√ÅLISE DE MELHORIAS:")
        print(f"   Arquivos com melhorias na densidade: {improved_files}/{len(comparisons)}")
        print(f"   Taxa de melhoria: {improvement_rate:.1f}%")
        print(f"   Melhoria m√©dia na densidade: {avg_density_improvement:+.3f}")
    
    # Melhores e piores casos
    print(f"\nüèÜ MELHORES CASOS (Top 5):")
    successful_results.sort(key=lambda x: x['quality_score'], reverse=True)
    for i, result in enumerate(successful_results[:5]):
        print(f"   {i+1}. {result['filename']} - Score: {result['quality_score']}/10")
    
    print(f"\n‚ö†Ô∏è PIORES CASOS (Bottom 5):")
    for i, result in enumerate(successful_results[-5:]):
        print(f"   {i+1}. {result['filename']} - Score: {result['quality_score']}/10")
    
    # Casos problem√°ticos (se houver)
    failed_results = [r for r in results if not r['success']]
    if failed_results:
        print(f"\n‚ùå CASOS PROBLEM√ÅTICOS:")
        for result in failed_results:
            print(f"   - {result['filename']}: {result['error']}")
    
    # Salvar relat√≥rio JSON
    report_path = Path(output_dir) / "validation_report.json"
    report_data = {
        'timestamp': datetime.now().isoformat(),
        'summary': {
            'total_files': total_files,
            'successful_conversions': successful_conversions,
            'failed_conversions': failed_conversions,
            'success_rate': success_rate,
            'total_time': total_time,
            'avg_conversion_time': total_time/total_files if total_files > 0 else 0,
            'avg_quality_score': avg_quality,
            'avg_density': avg_density
        },
        'results': results
    }
    
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report_data, f, indent=2, ensure_ascii=False)
    
    print(f"\nüíæ Relat√≥rio salvo em: {report_path}")
    
    # Avalia√ß√£o final
    print(f"\nüéØ AVALIA√á√ÉO FINAL:")
    if success_rate >= 95 and avg_quality >= 7:
        print("üèÜ EXCELENTE: Melhorias validadas com sucesso!")
        print("‚úÖ Sistema pronto para uso em produ√ß√£o")
    elif success_rate >= 90 and avg_quality >= 6:
        print("üëç BOM: Melhorias funcionando bem")
        print("‚úÖ Sistema funcional com pequenos ajustes")
    elif success_rate >= 80:
        print("‚ö†Ô∏è MODERADO: Alguns problemas identificados")
        print("üîß Requer ajustes antes do uso em produ√ß√£o")
    else:
        print("‚ùå PROBLEM√ÅTICO: Muitas falhas")
        print("üîß Requer revis√£o significativa")

def main():
    """Fun√ß√£o principal"""
    print("üî¨ VALIDA√á√ÉO COMPLETA DE MELHORIAS - PDF TO MARKDOWN CONVERTER")
    print("="*60)
    
    # Executar valida√ß√£o
    successful, failed = validate_all_improvements()
    
    if successful > 0:
        print(f"\n‚úÖ VALIDA√á√ÉO CONCLU√çDA!")
        print(f"Sucessos: {successful}, Falhas: {failed}")
    else:
        print(f"\n‚ùå VALIDA√á√ÉO FALHOU!")
        print("Nenhuma convers√£o bem-sucedida")

if __name__ == "__main__":
    main()
