#!/usr/bin/env python3
"""
Processamento Debug de todos os 44 PDFs
An√°lise cr√≠tica completa: dados extra√≠dos + resultados Markdown
"""

import os
import json
import time
from pathlib import Path
from datetime import datetime
from converter.pipeline import ConversionPipeline

# Configura√ß√µes
PDF_DIR = "/home/andrade/Documentos/Meus Ebooks/Genesis: The Correct Timeline/Referencias em PDF"
MARKDOWN_DIR = "/home/andrade/Documentos/Meus Ebooks/Genesis: The Correct Timeline/Referencias em Markdown"
DEBUG_OUTPUT_DIR = Path("debug_analysis")

# Criar diret√≥rio de debug
DEBUG_OUTPUT_DIR.mkdir(exist_ok=True)

def get_all_pdfs():
    """Obt√©m todos os PDFs do diret√≥rio"""
    pdf_files = list(Path(PDF_DIR).glob("*.pdf"))
    return sorted(pdf_files)

def analyze_extracted_data(raw_text, tables, images, font_info):
    """An√°lise detalhada dos dados extra√≠dos do PDF"""
    analysis = {
        'raw_text_length': len(raw_text),
        'text_lines': len(raw_text.split('\n')),
        'text_words': len(raw_text.split()),
        'tables_count': len(tables),
        'images_count': len(images),
        'font_info_count': len(font_info),
        'issues': []
    }
    
    # Problemas no texto extra√≠do
    lines = raw_text.split('\n')
    
    # 1. Linhas vazias excessivas
    empty_lines = len([l for l in lines if not l.strip()])
    empty_line_ratio = empty_lines / len(lines) if lines else 0
    if empty_line_ratio > 0.3:
        analysis['issues'].append(f"Muitas linhas vazias: {empty_line_ratio:.1%}")
    
    # 2. Linhas muito curtas (fragmenta√ß√£o)
    short_lines = len([l for l in lines if len(l.strip()) < 5 and l.strip()])
    if short_lines > len(lines) * 0.2:
        analysis['issues'].append(f"Muitas linhas curtas: {short_lines} linhas")
    
    # 3. Palavras repetidas excessivamente
    words = raw_text.split()
    word_freq = {}
    for word in words:
        word_freq[word.lower()] = word_freq.get(word.lower(), 0) + 1
    
    max_repetitions = max(word_freq.values()) if word_freq else 0
    if max_repetitions > 100:
        analysis['issues'].append(f"Palavra muito repetida: {max_repetitions}x")
    
    # 4. Caracteres estranhos
    strange_chars = len([c for c in raw_text if ord(c) > 127 and c not in '√°√©√≠√≥√∫√¢√™√Æ√¥√ª√£√µ√ß'])
    if strange_chars > len(raw_text) * 0.05:
        analysis['issues'].append(f"Muitos caracteres estranhos: {strange_chars}")
    
    # 5. Texto muito pequeno
    if len(raw_text) < 1000:
        analysis['issues'].append(f"Texto muito pequeno: {len(raw_text)} chars")
    
    # 6. Duplica√ß√£o de conte√∫do
    if len(raw_text) > 50000:
        analysis['issues'].append("Poss√≠vel duplica√ß√£o de conte√∫do (texto muito longo)")
    
    return analysis

def analyze_markdown_output(content):
    """An√°lise detalhada do output Markdown"""
    analysis = {
        'total_length': len(content),
        'total_lines': len(content.split('\n')),
        'content_lines': len([l for l in content.split('\n') if l.strip()]),
        'headers': len([l for l in content.split('\n') if l.strip().startswith('#')]),
        'lists': len([l for l in content.split('\n') if l.strip().startswith(('-', '‚Ä¢', '*', '1.', '2.'))]),
        'issues': []
    }
    
    lines = content.split('\n')
    
    # 1. Estrutura Markdown
    if analysis['headers'] == 0:
        analysis['issues'].append("Nenhum cabe√ßalho Markdown detectado")
    elif analysis['headers'] < 3:
        analysis['issues'].append(f"Poucos cabe√ßalhos: {analysis['headers']}")
    
    # 2. Densidade de conte√∫do
    density = analysis['content_lines'] / analysis['total_lines'] if analysis['total_lines'] > 0 else 0
    if density < 0.3:
        analysis['issues'].append(f"Baixa densidade de conte√∫do: {density:.1%}")
    
    # 3. Comprimento das linhas
    line_lengths = [len(l) for l in lines if l.strip()]
    if line_lengths:
        avg_length = sum(line_lengths) / len(line_lengths)
        if avg_length < 20:
            analysis['issues'].append(f"Linhas muito curtas (m√©dia: {avg_length:.1f} chars)")
        elif avg_length > 200:
            analysis['issues'].append(f"Linhas muito longas (m√©dia: {avg_length:.1f} chars)")
    
    # 4. Repeti√ß√µes
    seen_lines = set()
    repeated_lines = 0
    for line in lines:
        if line.strip():
            normalized = line.strip().lower()
            if normalized in seen_lines:
                repeated_lines += 1
            else:
                seen_lines.add(normalized)
    
    if repeated_lines > analysis['content_lines'] * 0.1:
        analysis['issues'].append(f"Muitas linhas repetidas: {repeated_lines}")
    
    # 5. Formata√ß√£o espec√≠fica
    if '```' in content:
        analysis['issues'].append("Detectados blocos de c√≥digo (pode indicar erro de formata√ß√£o)")
    
    # 6. Conte√∫do vazio ou muito pequeno
    if len(content) < 500:
        analysis['issues'].append(f"Conte√∫do muito pequeno: {len(content)} chars")
    
    return analysis

def create_detailed_report(pdf_name, extracted_analysis, markdown_analysis, ocr_info, conversion_time):
    """Cria relat√≥rio detalhado para um PDF"""
    report = f"""# An√°lise Debug: {pdf_name}

## Informa√ß√µes Gerais
- **Data/Hora**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **Tempo de Convers√£o**: {conversion_time:.2f}s
- **OCR Aplicado**: {ocr_info['applied']}
- **P√°ginas OCR**: {ocr_info['pages']}

## An√°lise dos Dados Extra√≠dos

### Estat√≠sticas B√°sicas
- **Tamanho do texto**: {extracted_analysis['raw_text_length']:,} caracteres
- **Linhas de texto**: {extracted_analysis['text_lines']:,}
- **Palavras**: {extracted_analysis['text_words']:,}
- **Tabelas**: {extracted_analysis['tables_count']}
- **Imagens**: {extracted_analysis['images_count']}
- **Informa√ß√µes de fonte**: {extracted_analysis['font_info_count']}

### Problemas Detectados na Extra√ß√£o
"""
    
    if extracted_analysis['issues']:
        for issue in extracted_analysis['issues']:
            report += f"- ‚ùå {issue}\n"
    else:
        report += "- ‚úÖ Nenhum problema detectado\n"
    
    report += f"""
## An√°lise do Output Markdown

### Estat√≠sticas B√°sicas
- **Tamanho total**: {markdown_analysis['total_length']:,} caracteres
- **Linhas totais**: {markdown_analysis['total_lines']:,}
- **Linhas com conte√∫do**: {markdown_analysis['content_lines']:,}
- **Cabe√ßalhos**: {markdown_analysis['headers']}
- **Listas**: {markdown_analysis['lists']}

### Problemas Detectados no Markdown
"""
    
    if markdown_analysis['issues']:
        for issue in markdown_analysis['issues']:
            report += f"- ‚ùå {issue}\n"
    else:
        report += "- ‚úÖ Nenhum problema detectado\n"
    
    # Calcular score de qualidade
    extracted_score = 100 - len(extracted_analysis['issues']) * 25
    markdown_score = 100 - len(markdown_analysis['issues']) * 25
    total_score = (extracted_score + markdown_score) / 2
    
    report += f"""
## Avalia√ß√£o Final
- **Score Extra√ß√£o**: {max(0, extracted_score):.1f}/100
- **Score Markdown**: {max(0, markdown_score):.1f}/100
- **Score Total**: {max(0, total_score):.1f}/100
- **Status**: {'‚úÖ EXCELENTE' if total_score >= 80 else '‚úÖ BOM' if total_score >= 60 else '‚ö†Ô∏è MODERADO' if total_score >= 40 else '‚ùå PROBLEM√ÅTICO'}

---
"""
    
    return report, total_score

def main():
    print("üîç PROCESSAMENTO DEBUG DE TODOS OS 44 PDFs")
    print("=" * 80)
    print("üìä An√°lise cr√≠tica completa: dados extra√≠dos + resultados Markdown")
    print("üìù Documenta√ß√£o detalhada de todos os problemas encontrados")
    print("=" * 80)
    
    # Obter todos os PDFs
    pdf_files = get_all_pdfs()
    print(f"üìö Encontrados {len(pdf_files)} arquivos PDF para processar")
    
    # Criar pipeline
    pipeline = ConversionPipeline(str(Path(MARKDOWN_DIR)))
    
    # Resultados gerais
    all_results = []
    successful_conversions = 0
    failed_conversions = 0
    
    # Relat√≥rio principal
    main_report = f"""# RELAT√ìRIO GERAL DE DEBUG - TODOS OS 44 PDFs

**Data/Hora**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**Total de PDFs**: {len(pdf_files)}

## Resumo Executivo

"""
    
    for i, pdf_path in enumerate(pdf_files, 1):
        pdf_name = pdf_path.name
        print(f"\nüìÑ [{i}/{len(pdf_files)}] PROCESSANDO: {pdf_name}")
        print("-" * 60)
        
        try:
            # Converter PDF
            conversion_start = time.time()
            
            output_filename = f"{pdf_name.replace('.pdf', '.md')}"
            output_path = pipeline.convert(str(pdf_path), output_filename)
            
            conversion_time = time.time() - conversion_start
            
            print(f"   ‚úÖ Convers√£o conclu√≠da: {conversion_time:.2f}s")
            
            # Obter dados da convers√£o
            ocr_applied = pipeline.current_data.get('ocr_applied', False)
            ocr_pages = pipeline.current_data.get('ocr_pages_processed', 0)
            
            # Analisar dados extra√≠dos (antes da convers√£o)
            print("   üîç Analisando dados extra√≠dos...")
            raw_text = pipeline.current_data.get('raw_text', '')
            tables = pipeline.current_data.get('tables', [])
            images = pipeline.current_data.get('images', [])
            font_info = pipeline.current_data.get('font_info', [])
            
            extracted_analysis = analyze_extracted_data(raw_text, tables, images, font_info)
            
            print(f"      Texto: {extracted_analysis['raw_text_length']:,} chars")
            print(f"      Problemas: {len(extracted_analysis['issues'])}")
            
            # Analisar output Markdown
            print("   üìù Analisando output Markdown...")
            with open(output_path, 'r', encoding='utf-8') as f:
                markdown_content = f.read()
            
            markdown_analysis = analyze_markdown_output(markdown_content)
            
            print(f"      Markdown: {markdown_analysis['total_length']:,} chars")
            print(f"      Problemas: {len(markdown_analysis['issues'])}")
            
            # Criar relat√≥rio detalhado
            ocr_info = {'applied': ocr_applied, 'pages': ocr_pages}
            detailed_report, score = create_detailed_report(
                pdf_name, extracted_analysis, markdown_analysis, ocr_info, conversion_time
            )
            
            # Salvar relat√≥rio individual
            report_filename = f"debug_{pdf_name.replace('.pdf', '.md')}"
            report_path = DEBUG_OUTPUT_DIR / report_filename
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(detailed_report)
            
            # Adicionar ao relat√≥rio principal
            all_results.append({
                'pdf_name': pdf_name,
                'score': score,
                'extracted_issues': len(extracted_analysis['issues']),
                'markdown_issues': len(markdown_analysis['issues']),
                'ocr_applied': ocr_applied,
                'ocr_pages': ocr_pages,
                'conversion_time': conversion_time,
                'report_file': report_filename
            })
            
            successful_conversions += 1
            
            # Status da convers√£o
            if score >= 80:
                status = "üèÜ EXCELENTE"
            elif score >= 60:
                status = "‚úÖ BOM"
            elif score >= 40:
                status = "‚ö†Ô∏è MODERADO"
            else:
                status = "‚ùå PROBLEM√ÅTICO"
            
            print(f"   üéØ Score: {score:.1f}/100 - {status}")
            
        except Exception as e:
            print(f"   ‚ùå ERRO: {e}")
            failed_conversions += 1
            
            all_results.append({
                'pdf_name': pdf_name,
                'score': 0,
                'extracted_issues': 999,
                'markdown_issues': 999,
                'ocr_applied': False,
                'ocr_pages': 0,
                'conversion_time': 0,
                'report_file': 'ERRO',
                'error': str(e)
            })
    
    # Gerar relat√≥rio final
    print(f"\nüìä GERANDO RELAT√ìRIO FINAL...")
    
    # Estat√≠sticas gerais
    successful_scores = [r['score'] for r in all_results if r['score'] > 0]
    avg_score = sum(successful_scores) / len(successful_scores) if successful_scores else 0
    
    excellent_count = len([r for r in all_results if r['score'] >= 80])
    good_count = len([r for r in all_results if 60 <= r['score'] < 80])
    moderate_count = len([r for r in all_results if 40 <= r['score'] < 60])
    poor_count = len([r for r in all_results if 0 < r['score'] < 40])
    error_count = len([r for r in all_results if r['score'] == 0 and 'error' in r])
    
    main_report += f"""
## Estat√≠sticas Gerais
- **Convers√µes bem-sucedidas**: {successful_conversions}/{len(pdf_files)} ({successful_conversions/len(pdf_files)*100:.1f}%)
- **Falhas**: {failed_conversions}/{len(pdf_files)} ({failed_conversions/len(pdf_files)*100:.1f}%)
- **Score m√©dio**: {avg_score:.1f}/100

## Distribui√ß√£o de Qualidade
- üèÜ **Excelente** (‚â•80): {excellent_count} PDFs
- ‚úÖ **Bom** (60-79): {good_count} PDFs  
- ‚ö†Ô∏è **Moderado** (40-59): {moderate_count} PDFs
- ‚ùå **Problem√°tico** (1-39): {poor_count} PDFs
- üí• **Erro**: {error_count} PDFs

## Problemas Mais Frequentes

### Problemas na Extra√ß√£o
"""
    
    # An√°lise de problemas frequentes
    all_extracted_issues = []
    all_markdown_issues = []
    
    for result in all_results:
        if 'error' not in result:
            # Ler relat√≥rio detalhado para extrair problemas
            report_path = DEBUG_OUTPUT_DIR / result['report_file']
            if report_path.exists():
                with open(report_path, 'r', encoding='utf-8') as f:
                    report_content = f.read()
                    
                    # Extrair problemas da extra√ß√£o
                    if "### Problemas Detectados na Extra√ß√£o" in report_content:
                        extraction_section = report_content.split("### Problemas Detectados na Extra√ß√£o")[1].split("##")[0]
                        issues = [line.strip()[4:] for line in extraction_section.split('\n') if line.strip().startswith('- ‚ùå')]
                        all_extracted_issues.extend(issues)
                    
                    # Extrair problemas do Markdown
                    if "### Problemas Detectados no Markdown" in report_content:
                        markdown_section = report_content.split("### Problemas Detectados no Markdown")[1].split("##")[0]
                        issues = [line.strip()[4:] for line in markdown_section.split('\n') if line.strip().startswith('- ‚ùå')]
                        all_markdown_issues.extend(issues)
    
    # Contar problemas mais frequentes
    from collections import Counter
    extracted_counter = Counter(all_extracted_issues)
    markdown_counter = Counter(all_markdown_issues)
    
    main_report += "\n**Problemas mais frequentes na extra√ß√£o:**\n"
    for issue, count in extracted_counter.most_common(5):
        percentage = count / successful_conversions * 100
        main_report += f"- {issue}: {count}x ({percentage:.1f}% dos PDFs)\n"
    
    main_report += "\n**Problemas mais frequentes no Markdown:**\n"
    for issue, count in markdown_counter.most_common(5):
        percentage = count / successful_conversions * 100
        main_report += f"- {issue}: {count}x ({percentage:.1f}% dos PDFs)\n"
    
    main_report += f"""
## Resultados Individuais

| PDF | Score | Extra√ß√£o | Markdown | OCR | Tempo | Status |
|-----|-------|----------|----------|-----|-------|--------|
"""
    
    # Ordenar por score
    sorted_results = sorted(all_results, key=lambda x: x['score'], reverse=True)
    
    for result in sorted_results:
        pdf_name = result['pdf_name']
        score = result['score']
        extracted_issues = result['extracted_issues']
        markdown_issues = result['markdown_issues']
        ocr_info = f"{result['ocr_pages']}p" if result['ocr_applied'] else "N√£o"
        time = f"{result['conversion_time']:.1f}s"
        
        if score >= 80:
            status = "üèÜ"
        elif score >= 60:
            status = "‚úÖ"
        elif score >= 40:
            status = "‚ö†Ô∏è"
        elif 'error' in result:
            status = "üí•"
        else:
            status = "‚ùå"
        
        main_report += f"| {pdf_name} | {score:.1f} | {extracted_issues} | {markdown_issues} | {ocr_info} | {time} | {status} |\n"
    
    main_report += f"""
## Arquivos de Relat√≥rio Individual
Todos os relat√≥rios detalhados est√£o dispon√≠veis em: `{DEBUG_OUTPUT_DIR}/`

## Pr√≥ximos Passos Recomendados
1. **Analisar PDFs com score < 60** para identificar padr√µes de problemas
2. **Revisar problemas mais frequentes** na extra√ß√£o e Markdown
3. **Implementar corre√ß√µes** para os problemas identificados
4. **Retestar** os PDFs problem√°ticos ap√≥s as corre√ß√µes
"""
    
    # Salvar relat√≥rio principal
    main_report_path = DEBUG_OUTPUT_DIR / "RELATORIO_GERAL_DEBUG.md"
    with open(main_report_path, 'w', encoding='utf-8') as f:
        f.write(main_report)
    
    # Salvar dados JSON para an√°lise posterior
    json_path = DEBUG_OUTPUT_DIR / "debug_results.json"
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(all_results, f, indent=2, ensure_ascii=False)
    
    print(f"\nüìä RESUMO FINAL:")
    print(f"   PDFs processados: {len(pdf_files)}")
    print(f"   Convers√µes bem-sucedidas: {successful_conversions}")
    print(f"   Falhas: {failed_conversions}")
    print(f"   Score m√©dio: {avg_score:.1f}/100")
    print(f"   Excelente/Bom: {excellent_count + good_count}/{len(pdf_files)}")
    
    print(f"\nüíæ RELAT√ìRIOS SALVOS:")
    print(f"   Relat√≥rio geral: {main_report_path}")
    print(f"   Dados JSON: {json_path}")
    print(f"   Relat√≥rios individuais: {DEBUG_OUTPUT_DIR}/")
    
    if avg_score >= 70:
        print(f"\nüéâ RESULTADO GERAL: EXCELENTE!")
    elif avg_score >= 50:
        print(f"\n‚úÖ RESULTADO GERAL: BOM")
    else:
        print(f"\n‚ö†Ô∏è RESULTADO GERAL: PRECISA DE MELHORIAS")

if __name__ == "__main__":
    main()
