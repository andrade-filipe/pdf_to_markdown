#!/usr/bin/env python3
"""
Teste da vers√£o otimizada do OCR seletivo
"""

import os
import json
import time
from pathlib import Path
from converter.pipeline import ConversionPipeline

# Configura√ß√µes
PDF_DIR = "/home/andrade/Documentos/Meus Ebooks/Genesis: The Correct Timeline/Referencias em PDF"
MARKDOWN_DIR = "/home/andrade/Documentos/Meus Ebooks/Genesis: The Correct Timeline/Referencias em Markdown"

# Casos problem√°ticos para teste
PROBLEMATIC_CASES = [
    "181014cronologia_ap.pdf",  # Preserva√ß√£o: 305.8% - muito repeti√ß√µes
    "Biostratigraphic Continuity and Earth History.pdf",  # Palavras repetidas: 1882x
    "coming-to-grips-with-genesis-ch6.pdf",  # Muitas linhas repetidas: 396
]

def analyze_content_quality(content):
    """An√°lise detalhada da qualidade do conte√∫do"""
    lines = content.split('\n')
    
    # Estat√≠sticas b√°sicas
    total_lines = len(lines)
    non_empty_lines = len([l for l in lines if l.strip()])
    empty_lines = total_lines - non_empty_lines
    
    # Densidade de conte√∫do
    density = non_empty_lines / total_lines if total_lines > 0 else 0
    
    # Contar repeti√ß√µes
    seen_lines = set()
    repeated_lines = 0
    line_freq = {}
    
    for line in lines:
        line = line.strip()
        if line:
            normalized = line.lower()
            line_freq[normalized] = line_freq.get(normalized, 0) + 1
            if normalized in seen_lines:
                repeated_lines += 1
            else:
                seen_lines.add(normalized)
    
    # An√°lise de palavras repetidas
    word_freq = {}
    all_text = ' '.join([line.strip() for line in lines if line.strip()])
    words = all_text.split()
    
    for word in words:
        word_lower = word.lower()
        if len(word_lower) > 2:
            word_freq[word_lower] = word_freq.get(word_lower, 0) + 1
    
    max_word_repetition = max(word_freq.values()) if word_freq else 0
    
    # An√°lise de duplica√ß√£o
    content_length = len(content)
    is_likely_duplicated = content_length > 50000
    
    # An√°lise de estrutura
    paragraphs = content.split('\n\n')
    avg_paragraph_length = sum(len(p) for p in paragraphs) / len(paragraphs) if paragraphs else 0
    
    # Calcular score de qualidade
    quality_score = 0
    
    # Densidade (0-25 pontos)
    quality_score += density * 25
    
    # Comprimento m√©dio das linhas (0-25 pontos)
    line_lengths = [len(l.strip()) for l in lines if l.strip()]
    avg_line_length = sum(line_lengths) / len(line_lengths) if line_lengths else 0
    quality_score += min(25, avg_line_length / 4)
    
    # Penalizar repeti√ß√µes (0-25 pontos)
    repetition_penalty = min(25, repeated_lines * 0.1 + max_word_repetition * 0.01)
    quality_score -= repetition_penalty
    
    # Qualidade da estrutura (0-25 pontos)
    if avg_paragraph_length > 200 and len(paragraphs) > 5:
        quality_score += 25
    elif avg_paragraph_length > 100 and len(paragraphs) > 3:
        quality_score += 20
    elif avg_paragraph_length > 50:
        quality_score += 15
    
    quality_score = max(0, quality_score)
    
    return {
        'total_lines': total_lines,
        'non_empty_lines': non_empty_lines,
        'empty_lines': empty_lines,
        'density': density,
        'repeated_lines': repeated_lines,
        'max_word_repetition': max_word_repetition,
        'content_length': content_length,
        'is_likely_duplicated': is_likely_duplicated,
        'avg_line_length': avg_line_length,
        'avg_paragraph_length': avg_paragraph_length,
        'paragraph_count': len(paragraphs),
        'quality_score': quality_score,
        'problematic_words': [word for word, count in word_freq.items() if count > 50]
    }

def main():
    print("üöÄ TESTE DO OCR SELETIVO OTIMIZADO")
    print("=" * 70)
    print("‚úÖ Algoritmo de combina√ß√£o inteligente aprimorado")
    print("‚úÖ Limpeza p√≥s-OCR mais agressiva")
    print("‚úÖ Detec√ß√£o e remo√ß√£o de duplica√ß√µes")
    print("=" * 70)
    
    # Criar pipeline com OCR seletivo otimizado
    pipeline = ConversionPipeline(str(Path(MARKDOWN_DIR)))
    
    results = {}
    
    for pdf_name in PROBLEMATIC_CASES:
        print(f"\nüìÑ TESTANDO OCR OTIMIZADO: {pdf_name}")
        print("-" * 60)
        
        pdf_path = Path(PDF_DIR) / pdf_name
        
        if not pdf_path.exists():
            print(f"‚ùå PDF n√£o encontrado: {pdf_path}")
            continue
        
        try:
            # Converter com OCR seletivo otimizado
            print("üîÑ Convertendo com OCR otimizado...")
            start_time = time.time()
            
            output_filename = f"{pdf_name.replace('.pdf', '_optimized.md')}"
            output_path = pipeline.convert(str(pdf_path), output_filename)
            
            conversion_time = time.time() - start_time
            
            print(f"   ‚úÖ Convers√£o conclu√≠da: {conversion_time:.2f}s")
            print(f"   üìÅ Arquivo: {output_path}")
            
            # Verificar se OCR foi aplicado
            ocr_applied = pipeline.current_data.get('ocr_applied', False)
            ocr_pages = pipeline.current_data.get('ocr_pages_processed', 0)
            
            if ocr_applied:
                print(f"   üîç OCR aplicado em {ocr_pages} p√°ginas")
            else:
                print(f"   üìù OCR n√£o necess√°rio - texto de boa qualidade")
            
            # Analisar resultado otimizado
            print("üìä Analisando resultado otimizado...")
            
            with open(output_path, 'r', encoding='utf-8') as f:
                optimized_content = f.read()
            
            optimized_analysis = analyze_content_quality(optimized_content)
            
            print(f"   üìä Linhas totais: {optimized_analysis['total_lines']:,}")
            print(f"   üìù Linhas com conte√∫do: {optimized_analysis['non_empty_lines']:,}")
            print(f"   üìà Densidade: {optimized_analysis['density']:.3f}")
            print(f"   üìè Comprimento m√©dio das linhas: {optimized_analysis['avg_line_length']:.1f}")
            print(f"   üîÑ Linhas repetidas: {optimized_analysis['repeated_lines']}")
            print(f"   üìö M√°x repeti√ß√£o de palavra: {optimized_analysis['max_word_repetition']}")
            print(f"   üìÑ Par√°grafos: {optimized_analysis['paragraph_count']}")
            print(f"   üìä Score de qualidade: {optimized_analysis['quality_score']:.1f}/100")
            
            # Comparar com vers√£o anterior
            old_md_path = Path(MARKDOWN_DIR) / f"{pdf_name.replace('.pdf', '.md')}"
            
            if old_md_path.exists():
                print("\nüìÑ Comparando com vers√£o anterior...")
                
                with open(old_md_path, 'r', encoding='utf-8') as f:
                    old_content = f.read()
                
                old_analysis = analyze_content_quality(old_content)
                
                improvement_density = optimized_analysis['density'] - old_analysis['density']
                improvement_repetitions = old_analysis['repeated_lines'] - optimized_analysis['repeated_lines']
                improvement_word_repetitions = old_analysis['max_word_repetition'] - optimized_analysis['max_word_repetition']
                improvement_quality = optimized_analysis['quality_score'] - old_analysis['quality_score']
                
                print(f"   üìà Melhoria na densidade: {improvement_density:+.3f}")
                print(f"   üîÑ Redu√ß√£o de linhas repetidas: {improvement_repetitions:+d}")
                print(f"   üìö Redu√ß√£o de palavras repetidas: {improvement_word_repetitions:+d}")
                print(f"   üéØ Melhoria no score de qualidade: {improvement_quality:+.1f}")
                
                # Verificar se o tamanho foi reduzido (menos duplica√ß√£o)
                size_reduction = (len(old_content) - len(optimized_content)) / len(old_content) * 100
                print(f"   üìâ Redu√ß√£o no tamanho: {size_reduction:+.1f}%")
                
                if improvement_quality > 10 or improvement_word_repetitions > 100:
                    print("   üöÄ MELHORIA SIGNIFICATIVA DETECTADA!")
                elif improvement_quality > 0:
                    print("   ‚úÖ Melhoria moderada detectada")
                else:
                    print("   ‚ö†Ô∏è Nenhuma melhoria detectada")
            
            # Detectar problemas remanescentes
            problems = []
            
            if optimized_analysis['repeated_lines'] > 50:
                problems.append(f"Muitas linhas repetidas ({optimized_analysis['repeated_lines']})")
            
            if optimized_analysis['max_word_repetition'] > 200:
                problems.append(f"Palavras muito repetidas (m√°x: {optimized_analysis['max_word_repetition']})")
            
            if optimized_analysis['is_likely_duplicated']:
                problems.append("Poss√≠vel duplica√ß√£o de conte√∫do")
            
            if optimized_analysis['quality_score'] < 50:
                problems.append(f"Score de qualidade baixo ({optimized_analysis['quality_score']:.1f}/100)")
            
            if problems:
                print(f"   ‚ö†Ô∏è Problemas remanescentes:")
                for problem in problems:
                    print(f"      - {problem}")
                    
                if optimized_analysis['problematic_words']:
                    print(f"   üîç Palavras problem√°ticas: {optimized_analysis['problematic_words'][:5]}...")
            else:
                print("   ‚úÖ Nenhum problema detectado!")
            
            results[pdf_name] = {
                'optimized_analysis': optimized_analysis,
                'ocr_applied': ocr_applied,
                'ocr_pages': ocr_pages,
                'conversion_time': conversion_time,
                'problems': problems,
                'improvements': {
                    'density_improvement': improvement_density if old_md_path.exists() else 0,
                    'repetition_reduction': improvement_repetitions if old_md_path.exists() else 0,
                    'word_repetition_reduction': improvement_word_repetitions if old_md_path.exists() else 0,
                    'quality_improvement': improvement_quality if old_md_path.exists() else 0,
                    'size_reduction': size_reduction if old_md_path.exists() else 0
                }
            }
            
        except Exception as e:
            print(f"   ‚ùå Erro na convers√£o: {e}")
            results[pdf_name] = {'error': str(e)}
    
    # Resumo dos resultados
    print("\nüéØ RESUMO DOS RESULTADOS OTIMIZADOS")
    print("=" * 70)
    
    successful_tests = 0
    ocr_used = 0
    significant_improvements = 0
    moderate_improvements = 0
    
    for pdf_name, result in results.items():
        if 'error' not in result:
            successful_tests += 1
            
            if result['ocr_applied']:
                ocr_used += 1
            
            analysis = result['optimized_analysis']
            improvements = result['improvements']
            
            # Determinar status da melhoria
            if improvements['quality_improvement'] > 10 or improvements['word_repetition_reduction'] > 100:
                status = "üöÄ SIGNIFICATIVAMENTE MELHORADO"
                significant_improvements += 1
            elif improvements['quality_improvement'] > 0:
                status = "‚úÖ MELHORADO"
                moderate_improvements += 1
            elif improvements['quality_improvement'] == 0 and improvements['word_repetition_reduction'] == 0:
                status = "üîÑ IGUAL"
            else:
                status = "‚ö†Ô∏è PIORADO"
            
            ocr_info = f"OCR:{result['ocr_pages']}p" if result['ocr_applied'] else "SEM OCR"
            quality_info = f"Q:{analysis['quality_score']:.0f}"
            
            print(f"   {pdf_name}: {status} [{ocr_info}] [{quality_info}]")
            print(f"      Densidade: {analysis['density']:.3f} (Œî{improvements['density_improvement']:+.3f})")
            print(f"      Repeti√ß√µes: {analysis['repeated_lines']} (Œî{improvements['repetition_reduction']:+d})")
            print(f"      Palavras repetidas: {analysis['max_word_repetition']} (Œî{improvements['word_repetition_reduction']:+d})")
            print(f"      Score: {analysis['quality_score']:.1f}/100 (Œî{improvements['quality_improvement']:+.1f})")
            print(f"      Tamanho: {analysis['content_length']:,} chars (Œî{improvements['size_reduction']:+.1f}%)")
        else:
            print(f"   {pdf_name}: ‚ùå ERRO - {result['error']}")
    
    print(f"\nüìä ESTAT√çSTICAS FINAIS:")
    print(f"   Testes bem-sucedidos: {successful_tests}/{len(PROBLEMATIC_CASES)}")
    print(f"   OCR utilizado: {ocr_used}/{successful_tests}")
    print(f"   Melhorias significativas: {significant_improvements}/{successful_tests}")
    print(f"   Melhorias moderadas: {moderate_improvements}/{successful_tests}")
    print(f"   Total de melhorias: {significant_improvements + moderate_improvements}/{successful_tests}")
    
    # Salvar resultados
    output_file = "ocr_optimized_test.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"\nüíæ Resultados salvos em: {output_file}")
    
    # Avalia√ß√£o final
    improvement_rate = (significant_improvements + moderate_improvements) / successful_tests if successful_tests > 0 else 0
    
    if improvement_rate >= 0.8:
        print(f"\nüéâ EXCELENTE: Melhorias em {improvement_rate*100:.0f}% dos casos!")
        print("   ‚úÖ OCR seletivo otimizado funcionando perfeitamente!")
    elif improvement_rate >= 0.6:
        print(f"\n‚úÖ BOM: Melhorias em {improvement_rate*100:.0f}% dos casos!")
        print("   üîß Pequenos ajustes ainda necess√°rios")
    elif improvement_rate >= 0.4:
        print(f"\n‚ö†Ô∏è MODERADO: Melhorias em {improvement_rate*100:.0f}% dos casos!")
        print("   üöß Ajustes significativos necess√°rios")
    else:
        print(f"\n‚ùå BAIXO: Melhorias em apenas {improvement_rate*100:.0f}% dos casos!")
        print("   üîÑ Revis√£o completa do algoritmo necess√°ria")

if __name__ == "__main__":
    main()
