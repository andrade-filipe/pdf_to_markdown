#!/usr/bin/env python3
"""AnÃ¡lise dos resultados mais recentes das conversÃµes"""

import os
import re
from pathlib import Path

def analyze_markdown_files():
    """Analisa os arquivos Markdown gerados mais recentemente"""
    
    output_dir = "/home/andrade/Documentos/Meus Ebooks/Genesis: The Correct Timeline/Referencias em Markdown"
    
    # Listar arquivos mais recentes
    md_files = list(Path(output_dir).glob("*.md"))
    md_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
    
    print(f"Analisando {len(md_files)} arquivos Markdown...")
    print("=" * 80)
    
    total_stats = {
        'total_files': len(md_files),
        'total_lines': 0,
        'total_headers': 0,
        'total_duplicates': 0,
        'academic_metadata_headers': 0,
        'files_with_issues': []
    }
    
    # PadrÃµes para detectar metadados acadÃªmicos
    academic_patterns = [
        'Proceedings', 'Volume', 'Article', 'Print Reference', 'DOI:', 
        'Available at:', 'Follow this and additional works', 'CedarCommons repository',
        'Recommended Citation', 'Browse the contents', 'University', 'College',
        'Copyright', 'All Rights Reserved', 'Journal Policies', 'Editorial Board'
    ]
    
    for i, md_file in enumerate(md_files[:10], 1):  # Analisar apenas os 10 mais recentes
        print(f"\n[{i}] Analisando: {md_file.name}")
        
        try:
            with open(md_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            lines = content.split('\n')
            headers = [line for line in lines if line.startswith('#')]
            
            # EstatÃ­sticas bÃ¡sicas
            file_stats = {
                'lines': len(lines),
                'headers': len(headers),
                'size_chars': len(content),
                'duplicate_lines': 0,
                'academic_metadata_headers': 0,
                'issues': []
            }
            
            # Verificar duplicaÃ§Ãµes
            seen_lines = set()
            for line in lines:
                line_stripped = line.strip()
                if line_stripped and line_stripped in seen_lines:
                    file_stats['duplicate_lines'] += 1
                seen_lines.add(line_stripped)
            
            # Verificar metadados acadÃªmicos marcados como headers
            for header in headers:
                for pattern in academic_patterns:
                    if pattern in header:
                        file_stats['academic_metadata_headers'] += 1
                        break
            
            # Detectar problemas especÃ­ficos
            if file_stats['academic_metadata_headers'] > 0:
                file_stats['issues'].append(f"Metadados acadÃªmicos como headers: {file_stats['academic_metadata_headers']}")
            
            if file_stats['duplicate_lines'] > len(lines) * 0.1:  # Mais de 10% duplicadas
                file_stats['issues'].append(f"Muitas duplicaÃ§Ãµes: {file_stats['duplicate_lines']} ({file_stats['duplicate_lines']/len(lines)*100:.1f}%)")
            
            if len(headers) == 0:
                file_stats['issues'].append("Sem headers detectados")
            
            if len(content) < 1000:
                file_stats['issues'].append("ConteÃºdo muito pequeno")
            
            # Exibir estatÃ­sticas
            print(f"  ğŸ“Š Linhas: {file_stats['lines']}")
            print(f"  ğŸ“‹ Headers: {file_stats['headers']}")
            print(f"  ğŸ“ Tamanho: {file_stats['size_chars']:,} chars")
            print(f"  ğŸ”„ DuplicaÃ§Ãµes: {file_stats['duplicate_lines']} ({file_stats['duplicate_lines']/len(lines)*100:.1f}%)")
            print(f"  âš ï¸  Metadados como headers: {file_stats['academic_metadata_headers']}")
            
            if file_stats['issues']:
                print(f"  âŒ Problemas:")
                for issue in file_stats['issues']:
                    print(f"     - {issue}")
                total_stats['files_with_issues'].append(md_file.name)
            else:
                print(f"  âœ… Sem problemas detectados")
            
            # Acumular estatÃ­sticas totais
            total_stats['total_lines'] += file_stats['lines']
            total_stats['total_headers'] += file_stats['headers']
            total_stats['total_duplicates'] += file_stats['duplicate_lines']
            total_stats['academic_metadata_headers'] += file_stats['academic_metadata_headers']
            
        except Exception as e:
            print(f"  âŒ ERRO ao analisar: {str(e)}")
    
    # EstatÃ­sticas finais
    print("\n" + "=" * 80)
    print("ESTATÃSTICAS GERAIS")
    print("=" * 80)
    print(f"ğŸ“ Arquivos analisados: {total_stats['total_files']}")
    print(f"ğŸ“Š Total de linhas: {total_stats['total_lines']:,}")
    print(f"ğŸ“‹ Total de headers: {total_stats['total_headers']}")
    print(f"ğŸ”„ Total de duplicaÃ§Ãµes: {total_stats['total_duplicates']} ({(total_stats['total_duplicates']/total_stats['total_lines'])*100:.1f}%)")
    print(f"âš ï¸  Metadados como headers: {total_stats['academic_metadata_headers']}")
    print(f"âŒ Arquivos com problemas: {len(total_stats['files_with_issues'])}")
    
    if total_stats['files_with_issues']:
        print(f"\nğŸ“ Arquivos com problemas:")
        for file_name in total_stats['files_with_issues']:
            print(f"  - {file_name}")
    
    # AvaliaÃ§Ã£o geral
    print(f"\nğŸ¯ AVALIAÃ‡ÃƒO GERAL:")
    if len(total_stats['files_with_issues']) == 0:
        print("  ğŸ‰ EXCELENTE! Todos os arquivos estÃ£o sem problemas.")
    elif len(total_stats['files_with_issues']) < total_stats['total_files'] * 0.3:
        print("  ğŸ‘ BOM! Menos de 30% dos arquivos tÃªm problemas.")
    elif len(total_stats['files_with_issues']) < total_stats['total_files'] * 0.7:
        print("  âš ï¸  REGULAR. Entre 30-70% dos arquivos tÃªm problemas.")
    else:
        print("  âŒ PROBLEMÃTICO. Mais de 70% dos arquivos tÃªm problemas.")
    
    print(f"\nğŸ“ˆ Taxa de duplicaÃ§Ã£o mÃ©dia: {(total_stats['total_duplicates']/total_stats['total_lines'])*100:.1f}%")
    print(f"ğŸ“‹ Headers por arquivo: {total_stats['total_headers']/min(10, total_stats['total_files']):.1f}")
    print(f"ğŸ“Š Linhas por arquivo: {total_stats['total_lines']/min(10, total_stats['total_files']):.1f}")

if __name__ == "__main__":
    analyze_markdown_files()

